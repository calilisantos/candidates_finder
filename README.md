# Boas vindas ao **candidates_finder!**

Para executar o projeto, observe as orienta√ß√µes descritas a seguir, e se tiver qualquer d√∫vida, sugest√£o, contribui√ß√£o, considere abrir uma issue ou entrar em contato. üöÄ

Aqui voc√™ vai encontrar os detalhes de como est√° estruturado e foi desenvolvido o projeto.

# <a id='topicos'>T√≥picos</a>
- [Desenvolvimento](#desenvolvimento)
  - [Objetivo](#objetivo)
  - [Estrutura do projeto](#estrutura)
  - [Tecnologias utilizadas](#tecnologias)
- [Orienta√ß√µes](#orientacoes)
  - [Executando o projeto](#execucao)
    - [1. Sem o docker](#sem-docker)
    - [2. Com o docker](#com-docker)
  - [Linter](#linter)
  - [Testes](#testes)
- [Implementa√ß√µes](#implementacoes)
  - [Contextualizando](#contextualizando)
  - [Vis√£o do app](#consumindo)
- [Pr√≥ximos passos](#next)

# <a id='desenvolvimento'>[Desenvolvimento](#topicos)</a>

<strong><a id='objetivo'>[Objetivo](#topicos)</a></strong>

  O **objetivo** √© criar um relat√≥rio em `csv` com potenciais candidatos a um processo seletivo, para um time de [Recrutamento e Sele√ß√£o](#contextualizando).
  
  Para isso, foi feita a leitura e transforma√ß√£o dos dados com o `Pyspark`, ferramenta de processamento de big data; e a `requests`, solu√ß√£o python para requisi√ß√µes web.

  ---

<strong><a id='estrutura'>[Estrutura do projeto](#topicos)</a></strong>

Pretendeu-se utilizar a `screaming-architecture` para a organiza√ß√£o do projeto, com a divis√£o em camadas e a separa√ß√£o de responsabilidades dos m√≥dulos da aplica√ß√£o.

* **Na pasta [candidates_finder](candidates_finder) est√£o os diret√≥rios:**
  * **[configs](candidates_finder/configs)** com os arquivos de configura√ß√£o e regras de neg√≥cio da execu√ß√£o do c√≥digo-fonte;
  * **[models](candidates_finder/model)** com a [camada](candidates_finder/model/read.py) que interage com a fonte de dados do aplicativo;
  * **[services](candidates_finder/service)** com a que aplica as [transforma√ß√µes dos dados](candidates_finder/service/transform.py) e [cria√ß√£o do relat√≥rio dos candidatos](candidates_finder/service/report.py);
  * **E o arquivo:**
    * **[main.py](candidates_finder/main.py)** com a classe **Main**, executora do c√≥digo-fonte da aplica√ß√£o.
* **Na pasta [docs](docs) est√£o os arquivos com a documenta√ß√£o do projeto.**
* **A pasta [output](output) √© criada para gera√ß√£o do relat√≥rio dos candidatos.**
* **Na pasta [tests](tests) est√£o os arquivos com os testes das respectivas camadas do c√≥digo-fonte.**
* **E os arquivos:**
  * **[.env](.env)** com as vari√°veis de ambiente do projeto;
    >IMPORTANTE:<br/>Para execu√ß√£o do projeto, informe seu token PAT do github. Como criar o seu [aqui](https://docs.github.com/pt/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens#fine-grained-personal-access-token).
  * **[.gitignore](.gitignore)** com as regras de arquivos a serem ignorados pelo git;
  * **[playground.py](playground.ipynb)** notebook jupyter com o c√≥digo-fonte original, utilizado como vers√£o piloto do projeto;
  * **[docker-compose.yml](docker-compose.yml)** arquivo que possibilita a execu√ß√£o da aplica√ß√£o, orquestrando as imagens docker do `spark` e `python`;
  * **[Dockerfile.candidates_finder](Dockerfile.candidates_finder)** container docker do `python` com as especifica√ß√µes necess√°rias para a aplica√ß√£o;
  * **[requirements.txt](requirements.txt)** arquivo com as depend√™ncias necess√°rias e utilizadas para execu√ß√£o do projeto;
  * **[tox.ini](tox.ini)** arquivo com a configura√ß√£o de uso da [an√°lise est√°tica do c√≥digo](#linter).

<strong><a id='tecnologias'>[Tecnologias utilizadas](#topicos)</a></strong>

  O projeto foi desenvolvido em Python, desde o processamento at√© a intera√ß√£o com a fonte dos dados.

  As solu√ß√µes utilizadas foram:

* **[Pyspark](https://spark.apache.org/docs/latest/api/python/index.html):**
  * Interface para execu√ß√£o do Spark em `python`, com todas as solu√ß√µes de processamento de dados da ferramenta;
* **[requests](https://requests.readthedocs.io/en/latest/):**
  * Biblioteca `python` para requisi√ß√µes web, utilizada para consumir a API do github;

>No arquivo de depend√™ncias, **[requirements.txt](requirements.txt)**, √© listada outras depend√™ncias acess√≥rias √† essas bibliotecas e tamb√©m utilizadas para **[an√°lise do c√≥digo](#linter)** e **[testes da aplica√ß√£o](#testes)**.
    
# <a id='orientacoes'>[Orienta√ß√µes](#topicos)</a>

<strong><a id='execucao'>[Executando o projeto](#topicos)</a></strong>

A aplica√ß√£o foi pensada para ser testada com o `Docker`, visando torn√°-la o mais agn√≥stica poss√≠vel.

√â poss√≠vel sua execu√ß√£o sem a ferramenta, com sugest√µes para os dois cen√°rios abaixo:

>**IMPORTANTE**<br/>Independente da escolha, ap√≥s clonar o projeto, entre com seu terminal na pasta criada:<br/>`cd candidates_finder`<br/>**Todas orienta√ß√µes abaixo, tem essa pasta como refer√™ncia.**

>**IMPORTANTE**<br/>Para os dois cen√°rios, √© necess√°rio informar seu token PAT do github no arquivo `.env`, ou exportar a vari√°vel de ambiente `GITHUB_PAT` com o valor do seu token.<br/>Sem esse passo o c√≥digo n√£o funcionar√°.

### <strong><a id='sem-docker'>[1. Execu√ß√£o sem o docker:](#topicos)</a></strong>

Nesse cen√°rio, √© necess√°rio que sua m√°quina possua instalado: i. o `spark` na vers√£o 3.4.0; ii. o kit de desenvolvimento java (`java jdk`) na vers√£o 8 ou superior; iii. e o `python`. Sobre essas ferramentas:

#### **i. Spark e jdk:**

  **√â fundamental o uso das vers√µes recomendadas do spark e java jdk** para integra√ß√£o com sucesso do spark<>pyspark. **Recomenda-se o jdk-11**, vers√£o utilizada na constru√ß√£o da aplica√ß√£o. 

  **N√£o foi testado, mas caso use uma vers√£o spark superior √† 3.0 localmente, n√£o espera-se incompatibilidade na execu√ß√£o do aplicativo.** Nesse cen√°rio, modifique a vers√£o do pyspark no arquivo requirements.txt antes do pr√≥ximo passo.

#### **ii. Python:** 
  
  O projeto foi constru√≠do com o python na vers√£o 3.10, por√©m **n√£o se espera indisponibilidades com sua execu√ß√£o √† partir da vers√£o 3.5.** 

  **Qualquer incompatibilidade com a vers√£o da sua m√°quina por favor informe.**

  Ainda, √© recomendada a instala√ß√£o pr√©via do gerenciador de pacotes `pip` para os passos a seguir:

  >**(Recomendado)** **Utilizar um ambiente virtual** com os seguintes comandos (nome `finder_venv` j√° considerado na ferramenta de [lint](#lint)):
  ```shell
  # cria o ambiente com o nome finder_venv:
  python3 -m venv finder_venv 
  # ativa o ambiente em terminais Linux e Mac:
  source finder_venv/bin/activate
  # ativa o ambiente em terminal Windows (cmd):
  finder_venv\Scripts\Activate
  ```
  >1.**Instalar depend√™ncias do projeto:**
  ```ps1
  pip install -r requirements.txt
  ```
  >2.**Setar PYTHONPATH:**
  ```shell
  export PYTHONPATH=./
  ```
  >3.**Executar projeto (na pasta criada com o clone):**
  ```bash
  python3 candidates_finder/main.py
  ```
  >4.**Executar projeto instanciando a classe Main (na pasta criada com o clone):**
  ```python
  from candidates_finder.main import Main

  Main().run()
  ```
  >5.**Executando testes (na pasta criada com o clone):**
  ```ps1
  pytest -v
  pytest --cov=tests/
  ```

### <strong><a id='com-docker'>[2. Execu√ß√£o com o docker:](#topicos)</a></strong>

>**IMPORTANTE**<br/>Nesse cen√°rio recomenda-se utilizar as vers√µes a seguir das ferramentas docker:<br/>`docker:25.0.3`  `docker-compose:1.29.2` <br/>**Verifique suas vers√µes com os comandos:** <br/>`docker version` e `docker-compose -v`

### Usando docker-compose para orquestrar imagens:
Com o docker-compose n√£o √© necess√°rio ter o `python`, `java` ou `spark` instalados localmente.

Passos para sua inicializa√ß√£o:
```bash
# na raiz do projeto, inicie os containers:
docker-compose up -d
# confirme que est√£o de p√©:
docker-compose ps
# caso tenha erro, ver logs do problema do container:
docker-compose logs candidates_finder # exemplo com container python
# vendo logs de todos os containers:
docker-compose logs
# vendo logs de todos os containers em tempo real:
docker-compose logs -f
# com a corre√ß√£o do erro, derrube os containers:
docker-compose down
# derrubando os containers for√ßando a limpeza dos seus volumes:
docker-compose down -v
# reiniciando containers for√ßando recria√ß√£o de um deles:
docker-compose up -d --force-recreate candidates_finder
# reiniciando containers for√ßando o rebuild das imagens:
docker-compose up --build 
```

Com o funcionamento dos containers, √© poss√≠vel executar os arquivos do projeto dessa forma:
```bash
# executando arquivo do container:
docker exec <container_name_or_id> python /caminho/para/seu/arquivo.py
# exemplo de execu√ß√£o dos testes do c√≥digo:
docker exec book-app pytest -v
# executando arquivos dentro do container:
docker exec -it <container_name> bash
# ex para o cluster do app:
docker exec -it book-app
```
>**IMPORTANTE**<br/>Nos logs de inicializa√ß√£o do container √© mostrada onde est√° localizada o execut√°vel java (JAVA_HOME) do container spark. Caso esse valor seja diferente do atual no docker-compose, modifique-o para execu√ß√£o com √™xito do projeto.
```dockerfile
environment:
  ...

  - JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64 # valor atual.
```

<strong><a id='linter'>[Linter](#topicos)</a></strong>

Foi utilizado o [**flake8**](https://flake8.pycqa.org/en/latest/) para fazer a an√°lise est√°tica do c√≥digo visando garantir as boas pr√°ticas e legibilidade do c√≥digo.

>Considere instalar as configura√ß√µes do flake8 no seu editor de texto para contribui√ß√µes no projeto.

Para executar o `flake8`, no seu terminal Mac ou Linux:
```bash
# na raiz do projeto:
flake8
# analisando um diret√≥rio em espec√≠fico:
flake8 candidates_finder/
# analisando um arquivo em espec√≠fico:
flake8 candidates_finder/main.py
```

<strong><a id='testes'>[Testes](#topicos)</a></strong>

Foi utilizado o **[pytest](https://docs.pytest.org/en/8.0.x/)** e **[unittest](https://docs.python.org/3/library/unittest.html)** para constru√ß√£o dos testes (de integra√ß√£o, unit√°rios e de carga atualmente) da aplica√ß√£o.

Mais detalhes na documenta√ß√£o dessas bibliotecas.

### Mande seu feedback sobre o projeto!

Se estiver a vontade, clone o reposit√≥rio e, seja com ou sem o Docker, execute, veja o deploy e me ajude a melhorar este projeto! Seu feedback ser√° super bem vindo!

# <a id='implementacoes'>[Implementa√ß√µes](#topicos)</a>

<strong><a id='contextualizando'>[Contextualizando](#topicos)</a></strong>

  O time de Recrutamento e Sele√ß√£o recebeu uma informa√ß√£o que os seguidores de uma determinada pessoa candidata no github podem ser potenciais para a vaga de engenharia de dados.
  Por isso, Recrutamento solicitou que fosse feito o web scraping usando a api do github para criar uma lista dessas pessoas candidatas e esse √© o objetivo do projeto.

  O relat√≥rio precisa conter ss seguintes campo:
  * name;
  * company;
  * blog;
  * email;
  * bio;
  * public_repos;
  * followers;
  * following;
  * created_at.

  Uma outra pessoa engenheira deu a dica que a melhor maneira de fazer essa tarefa seria usar esse endpoint: <https://api.github.com/users/{user}/followers> para conseguir a lista de followers e em seguida iterar em cada follower usando esse endpoint: <https://api.github.com/users/{user}>.

  Ainda foi solicitado que:
  * O campo `company` tenha removido o caractere `@` do in√≠cio do campo;
  * O campo `created_at` tenha a data formatada no padr√£o `dd/mm/yyyy`.

  E como recomenda√ß√µes finais temos:
  * Criar uma chave de api para se autenticar a api tem um rate limit pequeno;
  * Criar o c√≥digo em `pyspark`.
  
<strong><a id='consumindo'>[Vis√£o do app](#topicos)</a></strong>

  Com o uso do `docker-compose` como descrito [aqui](#com-docker), o comportamento esperado da aplica√ß√£o √©:

  ![candidates_finder gif](docs/candidates_finder.gif)

# <a id='next'>[Pr√≥ximos passos](#topicos)</a>

  As features mapeadas s√£o:

  * **Fazer requisi√ß√µes assincronamente**, para melhorar a performance da aplica√ß√£o;

  * **Ampliar cen√°rios de testes** garantindo o design da aplica√ß√£o;

  * **Construir uma esteira de CI/CD** para garantir a governan√ßa das implementa√ß√µes do projeto;

  * **Orquestrar o ambiente com Kubernetes**, adicionando uma op√ß√£o de disponibilidade da execu√ß√£o do projeto;

  * **Gerenciar os containers com helm**, adicionando uma op√ß√£o din√¢mica de disponibilidade da execu√ß√£o do projeto.

---
